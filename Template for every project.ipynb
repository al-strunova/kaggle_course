{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b480f0",
   "metadata": {},
   "source": [
    "# Introduction / Name of Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c1928",
   "metadata": {},
   "source": [
    "A proper introduction gives visitors the context needed to understand the project. This is also where you should introduce the dataset and explain the challenge you're solving.\n",
    "- What is the main challenge or topic your project addresses?\n",
    "- Which dataset are you using and how did you acquire it? (Also summarize the types of features and variables available in the dataset.)\n",
    "- What are the most important findings from your project? (Preview your results and draw visitors in.)\n",
    "- How does your project address the challenge? (Which data science and machine learning techniques do you use?)\n",
    "- Who are you and why is this project important or valuable to you? (What is your motivation for doing this project?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0d979",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "524e0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb440d4e",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b52bdc",
   "metadata": {},
   "source": [
    "Basic Information:\n",
    "- How many observations and features does your dataset have?\n",
    "- Do you understand each feature intuitively?\n",
    "- Do the values for each feature make sense? Are they on the right scale?\n",
    "- Do you anticipate issues with missing data?\n",
    "- Were your features read in as the correct datatype?\n",
    "\n",
    "Distributions:\n",
    "- Do each of the distributions make intuitive sense to you?\n",
    "- Do you anticipate any issues with outliers or sparse data?\n",
    "- Are there any surprising distributions you should take a closer look at?\n",
    "- Do the summary statistics confirm what you’ve seen from the charts?\n",
    "\n",
    "Feature Relationships (Segmentations & Correlations):\n",
    "- Have you segmented key categorical features and/or the target variable?\n",
    "- What have you learned about the relationships between your features?\n",
    "- Are there any surprising correlations (or non-correlations)?\n",
    "- Have you visualized your correlation matrix for easier reference?\n",
    "- Do you anticipate any helpful new features to engineer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e927fe",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c7602",
   "metadata": {},
   "source": [
    "Remember, proper data cleaning can make or break your project. Better data > fancier algorithms. Review the Cornerstone Projects if you need a refresher on the code.\n",
    "\n",
    "Unwanted Observations:\n",
    "- Have you dropped duplicate observations?\n",
    "- Have you dropped irrelevant observations?\n",
    "\n",
    "Structural Errors:\n",
    "- Are there any features that should be encoded as binary indicator variables?\n",
    "- Have you fixed typos and inconsistent capitalization in your categorical features?\n",
    "- Are there any classes in your categorical features that refer to the same thing? (e.g. “N/A” and “Not Applicable” appearing as two different classes)\n",
    "\n",
    "Outliers\n",
    "- Have you visually checked for any potential outliers to remove in your features?\n",
    "- Do you have a good reason to remove each outlier? (e.g. suspicious measurements, different population, different application)\n",
    "\n",
    "Missing Data\n",
    "- Have you labeled missing values in categorical features?\n",
    "- Have you flagged and filled missing values in numeric features?\n",
    "- Tip: There are certain situations where dropping observations with missing values is appropriate, such as if you only care about predicting observations that\n",
    "have a given feature value. For example, you might only wish to predict housing prices for single-family homes, in which case you would simply drop any\n",
    "observations that weren’t for single-family homes (including those with missing values for property type)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72396b1a",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdee4aa",
   "metadata": {},
   "source": [
    "Feature engineering is one of the best ways data scientists can improve model performance and add value into the applied machine learning process.\n",
    "\n",
    "Domain Knowledge:\n",
    "- Do you have prior expertise in your chosen domain? If not, have you done sufficient reading / research / preparation to understand it better?\n",
    "- Do you know anyone else in your network who also has domain expertise?\n",
    "- Based on your knowledge of the domain, are there any features you could engineer that would potentially improve the performance of your model?\n",
    "\n",
    "Heuristics:\n",
    "- Are there any interaction features you could create?\n",
    "- Are there any indicator features you could create?\n",
    "- Have you grouped sparse classes in your categorical features?\n",
    "- Do you need to do any form of data wrangling, such as aggregating data (i.e. rolling it up)?\n",
    "- Are there any ordinal categorical features you could encode as numeric?\n",
    "- Are there any potentially useful outside datasets you could merge in?\n",
    "\n",
    "Preparing the ABT:\n",
    "- Have you created dummy variables for your categorical features?\n",
    "- Have you dropped unused and/or redundant features? (e.g. ID columns, features that wouldn’t be available, text descriptions and metadata, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09eea0c",
   "metadata": {},
   "source": [
    "## Algorithm Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1be9a8",
   "metadata": {},
   "source": [
    "For your Capstone Project, you’ve probably already imported the relevant algorithms at the start of the project, under the Library Imports section. Therefore, you should use this\n",
    "section to explain your choices and showcase your understanding.\n",
    "- Why did you choose those algorithms?\n",
    "- What are their practical benefits?\n",
    "- What are the key hyperparameters to tune for your chosen algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae2648",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f800e",
   "metadata": {},
   "source": [
    "Once you’ve done the steps leading up to this one, model training should be straightforward and formulaic. Review the Cornerstone Projects if you need a refresher\n",
    "on the code.\n",
    "\n",
    "Data Spending:\n",
    "- Have you split your dataset into separate training and test sets?\n",
    "- Have you set a random seed for replicable results?\n",
    "- Do you understand the purpose and use-case of cross-validation?\n",
    "\n",
    "Pre-Processing & Pipelines:\n",
    "- Have you set up your modeling pipelines with the proper preprocessing steps?\n",
    "- Have you set random states for each algorithm to ensure replicable results?\n",
    "\n",
    "Hyperparameter Tuning:\n",
    "- Have you declared hyperparameter grids with reasonable hyperparameter values\n",
    "- try for each of your algorithms?\n",
    "- Have you set up GridSearchCV objects for each of your algorithms to perform cross-validation and tune hyperparameters?\n",
    "- Have you fit models using each of your algorithms?\n",
    "\n",
    "Winner Selection:\n",
    "- Which of your models had the best cross-validated score?\n",
    "- Which of your models performs the best on the test set?\n",
    "- Were you able to satisfy your win-condition for this project?\n",
    "- Do you need to use any additional performance metrics to evaluate your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085ece4",
   "metadata": {},
   "source": [
    "## Insights & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce19c80",
   "metadata": {},
   "source": [
    "Many people miss this crucial Insights & Analysis section. This comes at the end of your project, and it's really there to tie everything together. This is where you'd\n",
    "summarize your results, discuss your most important findings, and even explain how you would expand upon your project if you had more time and resources.\n",
    "- What were your key findings and results?\n",
    "- What was your winning model (if applicable)?\n",
    "- What did you personally learn by completing this project?\n",
    "- How would you expand upon or improve this project if you had more time and/or resources?\n",
    "- Are there any additional datasets that you would wish to acquire?\n",
    "- Were there any useful references that helped you complete your project? If so, you should add citations at the bottom."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
